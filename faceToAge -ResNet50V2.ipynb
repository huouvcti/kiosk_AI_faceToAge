{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f296fbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d5b071b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>ageRange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13677</th>\n",
       "      <td>./UTKFace/1_1_0_20170109191253730.jpg.chip.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>./UTKFace/1_1_2_20161219162225422.jpg.chip.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10405</th>\n",
       "      <td>./UTKFace/1_0_2_20161219200203132.jpg.chip.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11114</th>\n",
       "      <td>./UTKFace/1_0_1_20170110213647161.jpg.chip.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12083</th>\n",
       "      <td>./UTKFace/1_0_0_20161219154724341.jpg.chip.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16104</th>\n",
       "      <td>./UTKFace/90_1_0_20170120225317689.jpg.chip.jpg</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8015</th>\n",
       "      <td>./UTKFace/92_1_0_20170110183501116.jpg.chip.jpg</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23619</th>\n",
       "      <td>./UTKFace/90_1_0_20170120225510266.jpg.chip.jpg</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13965</th>\n",
       "      <td>./UTKFace/95_1_0_20170117174948948.jpg.chip.jpg</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6364</th>\n",
       "      <td>./UTKFace/99_1_2_20170117195405372.jpg.chip.jpg</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  path ageRange\n",
       "13677   ./UTKFace/1_1_0_20170109191253730.jpg.chip.jpg        0\n",
       "1447    ./UTKFace/1_1_2_20161219162225422.jpg.chip.jpg        0\n",
       "10405   ./UTKFace/1_0_2_20161219200203132.jpg.chip.jpg        0\n",
       "11114   ./UTKFace/1_0_1_20170110213647161.jpg.chip.jpg        0\n",
       "12083   ./UTKFace/1_0_0_20161219154724341.jpg.chip.jpg        0\n",
       "...                                                ...      ...\n",
       "16104  ./UTKFace/90_1_0_20170120225317689.jpg.chip.jpg       90\n",
       "8015   ./UTKFace/92_1_0_20170110183501116.jpg.chip.jpg       90\n",
       "23619  ./UTKFace/90_1_0_20170120225510266.jpg.chip.jpg       90\n",
       "13965  ./UTKFace/95_1_0_20170117174948948.jpg.chip.jpg       90\n",
       "6364   ./UTKFace/99_1_2_20170117195405372.jpg.chip.jpg       90\n",
       "\n",
       "[30000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_pickle(\"./dataset.pkl\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935507a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "813d87d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24000 validated image filenames belonging to 10 classes.\n",
      "Found 6000 validated image filenames belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "input_shape = (256, 256, 3)\n",
    "\n",
    "# 이미지 증강 세팅\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "\n",
    "# 학습 데이터셋 생성\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_data,\n",
    "    x_col='path',\n",
    "    y_col='ageRange',\n",
    "    target_size=input_shape[:2],\n",
    "    batch_size = batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# 검증 데이터셋 생성\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    test_data,\n",
    "    x_col='path',\n",
    "    y_col='ageRange',\n",
    "    target_size=input_shape[:2],\n",
    "    batch_size = batch_size,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97784f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c064fa9",
   "metadata": {},
   "source": [
    "<h1>전이 학습</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e913286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model):\n",
    "# Load the pretained model\n",
    "    kwargs =    {'input_shape':input_shape,\n",
    "                'include_top':False,\n",
    "                'weights':'imagenet',\n",
    "                'pooling':'avg'}\n",
    "    \n",
    "    pretrained_model = model(**kwargs)\n",
    "    pretrained_model.trainable = False # 레이어를 동결 시켜서 훈련중 손실을 최소화 한다.\n",
    "    \n",
    "    inputs = pretrained_model.input\n",
    "\n",
    "    x = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\n",
    "    x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0a259c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 19:51:05.448401: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-26 19:51:05.478172: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-26 19:51:05.478349: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-26 19:51:05.478993: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-26 19:51:05.479365: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-26 19:51:05.479529: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-26 19:51:05.479656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-26 19:51:05.866207: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-26 19:51:05.866380: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-26 19:51:05.866502: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-26 19:51:05.866612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9152 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "model = get_model(tf.keras.applications.ResNet152V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1c936cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0e6f581",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# 모델을 학습합니다.\n",
    "checkpoint_path = \"./ResNet152V2_best_model.h5\"\n",
    "checkpoint = ModelCheckpoint(checkpoint_path, \n",
    "                             monitor='val_accuracy', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8aea7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 19:51:37.105933: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - ETA: 0s - loss: 1.5649 - accuracy: 0.3803\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.44783, saving model to ./ResNet152V2_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uit-na/anaconda3/envs/hello/lib/python3.9/site-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 248s 323ms/step - loss: 1.5649 - accuracy: 0.3803 - val_loss: 1.3858 - val_accuracy: 0.4478\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - ETA: 0s - loss: 1.4181 - accuracy: 0.4296\n",
      "Epoch 00002: val_accuracy did not improve from 0.44783\n",
      "750/750 [==============================] - 240s 320ms/step - loss: 1.4181 - accuracy: 0.4296 - val_loss: 1.3541 - val_accuracy: 0.4438\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - ETA: 0s - loss: 1.3627 - accuracy: 0.4501\n",
      "Epoch 00003: val_accuracy improved from 0.44783 to 0.46883, saving model to ./ResNet152V2_best_model.h5\n",
      "750/750 [==============================] - 243s 323ms/step - loss: 1.3627 - accuracy: 0.4501 - val_loss: 1.3068 - val_accuracy: 0.4688\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - ETA: 0s - loss: 1.3340 - accuracy: 0.4632\n",
      "Epoch 00004: val_accuracy improved from 0.46883 to 0.47850, saving model to ./ResNet152V2_best_model.h5\n",
      "750/750 [==============================] - 239s 319ms/step - loss: 1.3340 - accuracy: 0.4632 - val_loss: 1.2731 - val_accuracy: 0.4785\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - ETA: 0s - loss: 1.2984 - accuracy: 0.4782\n",
      "Epoch 00005: val_accuracy improved from 0.47850 to 0.48767, saving model to ./ResNet152V2_best_model.h5\n",
      "750/750 [==============================] - 247s 330ms/step - loss: 1.2984 - accuracy: 0.4782 - val_loss: 1.2450 - val_accuracy: 0.4877\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - ETA: 0s - loss: 1.2842 - accuracy: 0.4875\n",
      "Epoch 00006: val_accuracy improved from 0.48767 to 0.50867, saving model to ./ResNet152V2_best_model.h5\n",
      "750/750 [==============================] - 261s 347ms/step - loss: 1.2842 - accuracy: 0.4875 - val_loss: 1.2136 - val_accuracy: 0.5087\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - ETA: 0s - loss: 1.2530 - accuracy: 0.4950\n",
      "Epoch 00007: val_accuracy did not improve from 0.50867\n",
      "750/750 [==============================] - 242s 322ms/step - loss: 1.2530 - accuracy: 0.4950 - val_loss: 1.2153 - val_accuracy: 0.5063\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - ETA: 0s - loss: 1.2344 - accuracy: 0.5053\n",
      "Epoch 00008: val_accuracy did not improve from 0.50867\n",
      "750/750 [==============================] - 255s 340ms/step - loss: 1.2344 - accuracy: 0.5053 - val_loss: 1.2760 - val_accuracy: 0.4855\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - ETA: 0s - loss: 1.2068 - accuracy: 0.5115\n",
      "Epoch 00009: val_accuracy improved from 0.50867 to 0.53483, saving model to ./ResNet152V2_best_model.h5\n",
      "750/750 [==============================] - 265s 353ms/step - loss: 1.2068 - accuracy: 0.5115 - val_loss: 1.1641 - val_accuracy: 0.5348\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - ETA: 0s - loss: 1.2127 - accuracy: 0.5118\n",
      "Epoch 00010: val_accuracy did not improve from 0.53483\n",
      "750/750 [==============================] - 264s 352ms/step - loss: 1.2127 - accuracy: 0.5118 - val_loss: 1.1668 - val_accuracy: 0.5265\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=test_generator,\n",
    "    epochs=10,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5ff134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aeb8c3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9cfa46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d76b43d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756c93c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d61eae1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12524ed7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "289c3607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ageRange</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18640</th>\n",
       "      <td>0</td>\n",
       "      <td>./UTKFace/26_1_3_20170117153712926.jpg.chip.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8878</th>\n",
       "      <td>0</td>\n",
       "      <td>./UTKFace/35_1_0_20170117092205487.jpg.chip.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7495</th>\n",
       "      <td>0</td>\n",
       "      <td>./UTKFace/30_1_2_20170116192643744.jpg.chip.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3851</th>\n",
       "      <td>0</td>\n",
       "      <td>./UTKFace/31_1_4_20170112235504601.jpg.chip.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3407</th>\n",
       "      <td>0</td>\n",
       "      <td>./UTKFace/36_0_1_20170120221302965.jpg.chip.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18557</th>\n",
       "      <td>3</td>\n",
       "      <td>./UTKFace/85_1_2_20170112204748587.jpg.chip.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14014</th>\n",
       "      <td>3</td>\n",
       "      <td>./UTKFace/85_1_0_20170110182918046.jpg.chip.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2277</th>\n",
       "      <td>3</td>\n",
       "      <td>./UTKFace/80_1_1_20170116153903211.jpg.chip.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18416</th>\n",
       "      <td>3</td>\n",
       "      <td>./UTKFace/85_0_0_20170111210559755.jpg.chip.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363</th>\n",
       "      <td>3</td>\n",
       "      <td>./UTKFace/80_1_1_20170117193146273.jpg.chip.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ageRange                                             path\n",
       "18640        0  ./UTKFace/26_1_3_20170117153712926.jpg.chip.jpg\n",
       "8878         0  ./UTKFace/35_1_0_20170117092205487.jpg.chip.jpg\n",
       "7495         0  ./UTKFace/30_1_2_20170116192643744.jpg.chip.jpg\n",
       "3851         0  ./UTKFace/31_1_4_20170112235504601.jpg.chip.jpg\n",
       "3407         0  ./UTKFace/36_0_1_20170120221302965.jpg.chip.jpg\n",
       "...        ...                                              ...\n",
       "18557        3  ./UTKFace/85_1_2_20170112204748587.jpg.chip.jpg\n",
       "14014        3  ./UTKFace/85_1_0_20170110182918046.jpg.chip.jpg\n",
       "2277         3  ./UTKFace/80_1_1_20170116153903211.jpg.chip.jpg\n",
       "18416        3  ./UTKFace/85_0_0_20170111210559755.jpg.chip.jpg\n",
       "1363         3  ./UTKFace/80_1_1_20170117193146273.jpg.chip.jpg\n",
       "\n",
       "[12000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_pickle(\"./new_dataset.pkl\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36233333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9600 validated image filenames belonging to 4 classes.\n",
      "Found 2400 validated image filenames belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "input_shape = (256, 256, 3)\n",
    "\n",
    "# 이미지 증강 세팅\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "\n",
    "# 학습 데이터셋 생성\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_data,\n",
    "    x_col='path',\n",
    "    y_col='ageRange',\n",
    "    target_size=input_shape[:2],\n",
    "    batch_size = batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# 검증 데이터셋 생성\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    test_data,\n",
    "    x_col='path',\n",
    "    y_col='ageRange',\n",
    "    target_size=input_shape[:2],\n",
    "    batch_size = batch_size,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6c2cce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model):\n",
    "# Load the pretained model\n",
    "    kwargs =    {'input_shape':input_shape,\n",
    "                'include_top':False,\n",
    "                'weights':'imagenet',\n",
    "                'pooling':'avg'}\n",
    "    \n",
    "    pretrained_model = model(**kwargs)\n",
    "    pretrained_model.trainable = False # 레이어를 동결 시켜서 훈련중 손실을 최소화 한다.\n",
    "    \n",
    "    inputs = pretrained_model.input\n",
    "\n",
    "    x = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\n",
    "    x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(4, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "204db001",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 23:32:10.566218: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-26 23:32:10.594313: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-26 23:32:10.594481: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-26 23:32:10.594944: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-26 23:32:10.595291: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-26 23:32:10.595433: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-26 23:32:10.595561: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-26 23:32:11.017839: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-26 23:32:11.018018: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-26 23:32:11.018143: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-26 23:32:11.018258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9179 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "model = get_model(tf.keras.applications.ResNet152V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cd668ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "# 일반 체크포인트 저장\n",
    "checkpoint_filepath = './model/ResNet50V2/checkpoint.{epoch:02d}-{val_accuracy:.2f}.h5'\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    save_best_only=False,\n",
    "    monitor='val_accuracy',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# best 체크포인트 저장\n",
    "# best_checkpoint_filepath = './model/ResNet50V2/best_checkpoint.{epoch:02d}-{val_loss:.2f}.h5'\n",
    "# best_checkpoint_callback = ModelCheckpoint(\n",
    "#     filepath=best_checkpoint_filepath,\n",
    "#     save_weights_only=True,\n",
    "#     save_best_only=True,\n",
    "#     monitor='val_loss',\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "best_checkpoint_filepath = './model/ResNet50V2/best.h5'\n",
    "best_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=best_checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    save_best_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# checkpoint_path = \"./model/ResNet50V2/best.h5\"\n",
    "# checkpoint = ModelCheckpoint(checkpoint_path, \n",
    "#                              monitor='val_accuracy', \n",
    "#                              verbose=1, \n",
    "#                              save_best_only=True, \n",
    "#                              mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8a8c7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "410e581f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.5581 - accuracy: 0.7589\n",
      "Epoch 00001: saving model to ./model/ResNet50V2/checkpoint.01-0.72.h5\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.74958\n",
      "300/300 [==============================] - 98s 327ms/step - loss: 0.5581 - accuracy: 0.7589 - val_loss: 0.6698 - val_accuracy: 0.7171\n",
      "Epoch 2/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.5640 - accuracy: 0.7530\n",
      "Epoch 00002: saving model to ./model/ResNet50V2/checkpoint.02-0.73.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.74958\n",
      "300/300 [==============================] - 97s 323ms/step - loss: 0.5640 - accuracy: 0.7530 - val_loss: 0.6569 - val_accuracy: 0.7254\n",
      "Epoch 3/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.5488 - accuracy: 0.7633\n",
      "Epoch 00003: saving model to ./model/ResNet50V2/checkpoint.03-0.73.h5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.74958\n",
      "300/300 [==============================] - 97s 324ms/step - loss: 0.5488 - accuracy: 0.7633 - val_loss: 0.6753 - val_accuracy: 0.7279\n",
      "Epoch 4/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.5623 - accuracy: 0.7551\n",
      "Epoch 00004: saving model to ./model/ResNet50V2/checkpoint.04-0.74.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.74958\n",
      "300/300 [==============================] - 97s 323ms/step - loss: 0.5623 - accuracy: 0.7551 - val_loss: 0.6106 - val_accuracy: 0.7408\n",
      "Epoch 5/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.5541 - accuracy: 0.7620\n",
      "Epoch 00005: saving model to ./model/ResNet50V2/checkpoint.05-0.74.h5\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.74958\n",
      "300/300 [==============================] - 97s 325ms/step - loss: 0.5541 - accuracy: 0.7620 - val_loss: 0.6288 - val_accuracy: 0.7350\n",
      "Epoch 6/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.5586 - accuracy: 0.7580\n",
      "Epoch 00006: saving model to ./model/ResNet50V2/checkpoint.06-0.74.h5\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.74958\n",
      "300/300 [==============================] - 99s 328ms/step - loss: 0.5586 - accuracy: 0.7580 - val_loss: 0.6283 - val_accuracy: 0.7396\n",
      "Epoch 7/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.5508 - accuracy: 0.7644\n",
      "Epoch 00007: saving model to ./model/ResNet50V2/checkpoint.07-0.72.h5\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.74958\n",
      "300/300 [==============================] - 98s 326ms/step - loss: 0.5508 - accuracy: 0.7644 - val_loss: 0.6572 - val_accuracy: 0.7200\n",
      "Epoch 8/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.5559 - accuracy: 0.7608\n",
      "Epoch 00008: saving model to ./model/ResNet50V2/checkpoint.08-0.74.h5\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.74958\n",
      "300/300 [==============================] - 98s 327ms/step - loss: 0.5559 - accuracy: 0.7608 - val_loss: 0.6200 - val_accuracy: 0.7421\n",
      "Epoch 9/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.5480 - accuracy: 0.7621\n",
      "Epoch 00009: saving model to ./model/ResNet50V2/checkpoint.09-0.75.h5\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.74958\n",
      "300/300 [==============================] - 98s 326ms/step - loss: 0.5480 - accuracy: 0.7621 - val_loss: 0.6303 - val_accuracy: 0.7454\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=test_generator,\n",
    "    epochs=100,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[checkpoint_callback, best_checkpoint_callback, early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb7ad93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85db8d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 이전에 학습한 모델 불러오기\n",
    "model = load_model('./model/ResNet50V2/best.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf675669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bc3ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "Jupyter.notebook.session.delete();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hello] *",
   "language": "python",
   "name": "conda-env-hello-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
