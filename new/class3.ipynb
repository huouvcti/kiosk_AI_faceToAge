{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a80dafbc",
   "metadata": {},
   "source": [
    "<h1>Class 3</h1>\n",
    "<br>\n",
    "- 나이분류 (20~59), (60~79), 80 이상\n",
    "- 동양인만"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4c60df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "import keras\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6909ce5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../UTKFace'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd66f6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "image = Image.open(data_dir+'/1_0_0_20161219140623097.jpg.chip.jpg')\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a31ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "938aed1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40_1_3_20170116191729090.jpg.chip.jpg</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41_0_3_20170119143544485.jpg.chip.jpg</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26_0_3_20170119180343596.jpg.chip.jpg</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54_1_3_20170105001159796.jpg.chip.jpg</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37_0_3_20170119202410749.jpg.chip.jpg</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3330</th>\n",
       "      <td>21_1_3_20170104222046054.jpg.chip.jpg</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3331</th>\n",
       "      <td>29_0_3_20170119183457486.jpg.chip.jpg</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3332</th>\n",
       "      <td>65_0_3_20170119203936910.jpg.chip.jpg</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3333</th>\n",
       "      <td>65_1_3_20170109143047483.jpg.chip.jpg</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3334</th>\n",
       "      <td>28_0_3_20170119194725939.jpg.chip.jpg</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3335 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  file_name  age\n",
       "0     40_1_3_20170116191729090.jpg.chip.jpg   40\n",
       "1     41_0_3_20170119143544485.jpg.chip.jpg   41\n",
       "2     26_0_3_20170119180343596.jpg.chip.jpg   26\n",
       "3     54_1_3_20170105001159796.jpg.chip.jpg   54\n",
       "4     37_0_3_20170119202410749.jpg.chip.jpg   37\n",
       "...                                     ...  ...\n",
       "3330  21_1_3_20170104222046054.jpg.chip.jpg   21\n",
       "3331  29_0_3_20170119183457486.jpg.chip.jpg   29\n",
       "3332  65_0_3_20170119203936910.jpg.chip.jpg   65\n",
       "3333  65_1_3_20170109143047483.jpg.chip.jpg   65\n",
       "3334  28_0_3_20170119194725939.jpg.chip.jpg   28\n",
       "\n",
       "[3335 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = []\n",
    "ages = []\n",
    "\n",
    "file_names = os.listdir(data_dir)\n",
    "for file_name in file_names:\n",
    "    test = file_name.split('_')\n",
    "    \n",
    "    if len(test) == 4:\n",
    "        age, gender, race, _ = file_name.split('_')\n",
    "        \n",
    "        if (int(age) >= 20 and int(age) < 100 and int(race) == 3 ):\n",
    "            files.append(file_name)\n",
    "            ages.append(int(age))\n",
    "            \n",
    "# 데이터 프레임 생성\n",
    "df = pd.DataFrame({'file_name': files, 'age': ages})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10dd873b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df['age'], bins=range(0, 100, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dced654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터셋을 읽어들입니다.\n",
    "data = df\n",
    "\n",
    "# 각 나이별로 데이터를 분할합니다.\n",
    "age_groups = [(20, 59), (60, 79), (80, 100)]\n",
    "age_data = [data[(data['age'] >= group[0]) & (data['age'] <= group[1])] for group in age_groups]\n",
    "\n",
    "# 각 나이 그룹에서 샘플링할 개수를 정합니다.\n",
    "target_size = 400\n",
    "sample_sizes = [target_size] * len(age_data)\n",
    "\n",
    "\n",
    "# 언더샘플링을 수행합니다.\n",
    "sampled_data = []\n",
    "for group, size in zip(age_data, sample_sizes):\n",
    "    if len(group) >= size:\n",
    "        sampled_group = resample(group, replace=False, n_samples=size, random_state=42)\n",
    "    else:\n",
    "        sampled_group = group\n",
    "    sampled_data.append(sampled_group)\n",
    "new_data = pd.concat(sampled_data)\n",
    "\n",
    "# 오버샘플링을 수행합니다.\n",
    "ros = RandomOverSampler(sampling_strategy='minority', random_state=42)\n",
    "X, y = new_data.iloc[:, :-1].values, new_data['age'].values\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "new_data = pd.concat([pd.DataFrame(X_resampled), pd.DataFrame(y_resampled, columns=['age'])], axis=1)\n",
    "\n",
    "# 각 나이 그룹에서 3000개씩 샘플링합니다.\n",
    "sampled_data = []\n",
    "for group, size in zip(age_data, sample_sizes):\n",
    "    if len(group) > size:\n",
    "        sampled_group = resample(group, replace=False, n_samples=size, random_state=42)\n",
    "    else:\n",
    "        sampled_group = group.sample(size, replace=True, random_state=42)\n",
    "    sampled_data.append(sampled_group)\n",
    "new_data = pd.concat(sampled_data)\n",
    "\n",
    "\n",
    "# 나이 분포를 시각화합니다.\n",
    "plt.hist(new_data['age'], bins=range(1, 120, 20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1d638fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>27_0_3_20170104200540418.jpg.chip.jpg</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2354</th>\n",
       "      <td>27_1_3_20170104232645690.jpg.chip.jpg</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>34_0_3_20170119200611509.jpg.chip.jpg</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>38_1_3_20170109140706612.jpg.chip.jpg</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>36_1_3_20170119202143325.jpg.chip.jpg</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>89_0_3_20170105180114246.jpg.chip.jpg</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2060</th>\n",
       "      <td>80_0_3_20170117174541085.jpg.chip.jpg</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>88_1_3_20170110182157752.jpg.chip.jpg</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2422</th>\n",
       "      <td>85_1_3_20170110183946188.jpg.chip.jpg</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3164</th>\n",
       "      <td>96_1_3_20170110180250210.jpg.chip.jpg</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  file_name  age\n",
       "1786  27_0_3_20170104200540418.jpg.chip.jpg   27\n",
       "2354  27_1_3_20170104232645690.jpg.chip.jpg   27\n",
       "328   34_0_3_20170119200611509.jpg.chip.jpg   34\n",
       "798   38_1_3_20170109140706612.jpg.chip.jpg   38\n",
       "1180  36_1_3_20170119202143325.jpg.chip.jpg   36\n",
       "...                                     ...  ...\n",
       "2222  89_0_3_20170105180114246.jpg.chip.jpg   89\n",
       "2060  80_0_3_20170117174541085.jpg.chip.jpg   80\n",
       "1748  88_1_3_20170110182157752.jpg.chip.jpg   88\n",
       "2422  85_1_3_20170110183946188.jpg.chip.jpg   85\n",
       "3164  96_1_3_20170110180250210.jpg.chip.jpg   96\n",
       "\n",
       "[1200 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e34b363",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = new_data.copy()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "agelist = [\n",
    "    (dataset['age'] < 60),\n",
    "    (dataset['age'] >= 60) & (dataset['age'] < 80),\n",
    "    (dataset['age'] >= 80)\n",
    "]\n",
    "\n",
    "'''\n",
    "0: 2~50대\n",
    "1: 6~70대\n",
    "2: 80대 이상\n",
    "'''\n",
    "ageRangeList = [0, 1, 2]\n",
    "\n",
    "dataset['ageRange'] = np.select(agelist, ageRangeList, default='')\n",
    "\n",
    "dataset['path'] = dataset['file_name'].apply(lambda x: f\"{data_dir}/{x}\")\n",
    "\n",
    "dataset = dataset.drop(['file_name', 'age'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ce0b129",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_pickle(\"./class3_dataset.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8042385e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 960 validated image filenames belonging to 3 classes.\n",
      "Found 240 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "input_shape = (200, 200, 3)\n",
    "\n",
    "# 이미지 증강 세팅\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "\n",
    "# 학습 데이터셋 생성\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_data,\n",
    "    x_col='path',\n",
    "    y_col='ageRange',\n",
    "    target_size=input_shape[:2],\n",
    "    batch_size = batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# 검증 데이터셋 생성\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    test_data,\n",
    "    x_col='path',\n",
    "    y_col='ageRange',\n",
    "    target_size=input_shape[:2],\n",
    "    batch_size = batch_size,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eef8e78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1875c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model):\n",
    "# Load the pretained model\n",
    "    kwargs =    {'input_shape':input_shape,\n",
    "                'include_top':False,\n",
    "                'weights':'imagenet',\n",
    "                'pooling':'avg'}\n",
    "    \n",
    "    pretrained_model = model(**kwargs)\n",
    "    pretrained_model.trainable = False # 레이어를 동결 시켜서 훈련중 손실을 최소화 한다.\n",
    "    \n",
    "    inputs = pretrained_model.input\n",
    "\n",
    "    layer1 = tf.keras.layers.Flatten()(pretrained_model.output)\n",
    "    layer2 = tf.keras.layers.Dense(1024, activation=\"relu\")(layer1)\n",
    "    drop1 = tf.keras.layers.Dropout(0.2)(layer2)\n",
    "    output_layer = tf.keras.layers.Dense(3, activation='softmax')(drop1)\n",
    "\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=output_layer)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "404ad635",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(tf.keras.applications.ResNet152V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69b7acad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# 모델을 학습합니다.\n",
    "checkpoint_path = \"./class3/best_model.h5\"\n",
    "checkpoint = ModelCheckpoint(checkpoint_path, \n",
    "                             monitor='val_accuracy', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e4ecca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "tensorboard_callback = TensorBoard(log_dir='./class3_logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d6a26a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uit-na/anaconda3/envs/hello/lib/python3.9/site-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 1.4045 - accuracy: 0.5760\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.80417, saving model to ./class3/best_model.h5\n",
      "30/30 [==============================] - 13s 291ms/step - loss: 1.4045 - accuracy: 0.5760 - val_loss: 0.5197 - val_accuracy: 0.8042\n",
      "Epoch 2/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.5715 - accuracy: 0.7625\n",
      "Epoch 00002: val_accuracy improved from 0.80417 to 0.86250, saving model to ./class3/best_model.h5\n",
      "30/30 [==============================] - 7s 235ms/step - loss: 0.5715 - accuracy: 0.7625 - val_loss: 0.4195 - val_accuracy: 0.8625\n",
      "Epoch 3/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.4535 - accuracy: 0.8188\n",
      "Epoch 00003: val_accuracy improved from 0.86250 to 0.87083, saving model to ./class3/best_model.h5\n",
      "30/30 [==============================] - 7s 233ms/step - loss: 0.4535 - accuracy: 0.8188 - val_loss: 0.3910 - val_accuracy: 0.8708\n",
      "Epoch 4/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.4215 - accuracy: 0.8229\n",
      "Epoch 00004: val_accuracy did not improve from 0.87083\n",
      "30/30 [==============================] - 6s 205ms/step - loss: 0.4215 - accuracy: 0.8229 - val_loss: 0.4067 - val_accuracy: 0.8500\n",
      "Epoch 5/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3734 - accuracy: 0.8396\n",
      "Epoch 00005: val_accuracy did not improve from 0.87083\n",
      "30/30 [==============================] - 6s 204ms/step - loss: 0.3734 - accuracy: 0.8396 - val_loss: 0.3620 - val_accuracy: 0.8500\n",
      "Epoch 6/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.4238 - accuracy: 0.8229\n",
      "Epoch 00006: val_accuracy did not improve from 0.87083\n",
      "30/30 [==============================] - 6s 204ms/step - loss: 0.4238 - accuracy: 0.8229 - val_loss: 0.4053 - val_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.4071 - accuracy: 0.8323\n",
      "Epoch 00007: val_accuracy did not improve from 0.87083\n",
      "30/30 [==============================] - 6s 204ms/step - loss: 0.4071 - accuracy: 0.8323 - val_loss: 0.3448 - val_accuracy: 0.8625\n",
      "Epoch 8/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3364 - accuracy: 0.8583\n",
      "Epoch 00008: val_accuracy improved from 0.87083 to 0.87500, saving model to ./class3/best_model.h5\n",
      "30/30 [==============================] - 7s 232ms/step - loss: 0.3364 - accuracy: 0.8583 - val_loss: 0.3781 - val_accuracy: 0.8750\n",
      "Epoch 9/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3547 - accuracy: 0.8573\n",
      "Epoch 00009: val_accuracy did not improve from 0.87500\n",
      "30/30 [==============================] - 6s 202ms/step - loss: 0.3547 - accuracy: 0.8573 - val_loss: 0.3751 - val_accuracy: 0.8458\n",
      "Epoch 10/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3373 - accuracy: 0.8625\n",
      "Epoch 00010: val_accuracy improved from 0.87500 to 0.89583, saving model to ./class3/best_model.h5\n",
      "30/30 [==============================] - 7s 232ms/step - loss: 0.3373 - accuracy: 0.8625 - val_loss: 0.3053 - val_accuracy: 0.8958\n",
      "Epoch 11/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3399 - accuracy: 0.8656\n",
      "Epoch 00011: val_accuracy did not improve from 0.89583\n",
      "30/30 [==============================] - 6s 204ms/step - loss: 0.3399 - accuracy: 0.8656 - val_loss: 0.3344 - val_accuracy: 0.8917\n",
      "Epoch 12/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3124 - accuracy: 0.8750\n",
      "Epoch 00012: val_accuracy did not improve from 0.89583\n",
      "30/30 [==============================] - 6s 205ms/step - loss: 0.3124 - accuracy: 0.8750 - val_loss: 0.3280 - val_accuracy: 0.8792\n",
      "Epoch 13/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3306 - accuracy: 0.8635\n",
      "Epoch 00013: val_accuracy did not improve from 0.89583\n",
      "30/30 [==============================] - 6s 204ms/step - loss: 0.3306 - accuracy: 0.8635 - val_loss: 0.3284 - val_accuracy: 0.8875\n",
      "Epoch 14/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.2739 - accuracy: 0.8958\n",
      "Epoch 00014: val_accuracy improved from 0.89583 to 0.91667, saving model to ./class3/best_model.h5\n",
      "30/30 [==============================] - 7s 233ms/step - loss: 0.2739 - accuracy: 0.8958 - val_loss: 0.2805 - val_accuracy: 0.9167\n",
      "Epoch 15/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3210 - accuracy: 0.8792\n",
      "Epoch 00015: val_accuracy did not improve from 0.91667\n",
      "30/30 [==============================] - 6s 205ms/step - loss: 0.3210 - accuracy: 0.8792 - val_loss: 0.3283 - val_accuracy: 0.8958\n",
      "Epoch 16/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.2645 - accuracy: 0.8885\n",
      "Epoch 00016: val_accuracy did not improve from 0.91667\n",
      "30/30 [==============================] - 6s 205ms/step - loss: 0.2645 - accuracy: 0.8885 - val_loss: 0.2766 - val_accuracy: 0.9125\n",
      "Epoch 17/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.2691 - accuracy: 0.8896\n",
      "Epoch 00017: val_accuracy improved from 0.91667 to 0.92500, saving model to ./class3/best_model.h5\n",
      "30/30 [==============================] - 7s 235ms/step - loss: 0.2691 - accuracy: 0.8896 - val_loss: 0.2562 - val_accuracy: 0.9250\n",
      "Epoch 18/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.2657 - accuracy: 0.8906\n",
      "Epoch 00018: val_accuracy did not improve from 0.92500\n",
      "30/30 [==============================] - 6s 204ms/step - loss: 0.2657 - accuracy: 0.8906 - val_loss: 0.3215 - val_accuracy: 0.8708\n",
      "Epoch 19/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.2978 - accuracy: 0.8729\n",
      "Epoch 00019: val_accuracy did not improve from 0.92500\n",
      "30/30 [==============================] - 6s 207ms/step - loss: 0.2978 - accuracy: 0.8729 - val_loss: 0.2714 - val_accuracy: 0.9000\n",
      "Epoch 20/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.2497 - accuracy: 0.9083\n",
      "Epoch 00020: val_accuracy did not improve from 0.92500\n",
      "30/30 [==============================] - 6s 207ms/step - loss: 0.2497 - accuracy: 0.9083 - val_loss: 0.2724 - val_accuracy: 0.9042\n",
      "Epoch 21/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.2755 - accuracy: 0.8854\n",
      "Epoch 00021: val_accuracy did not improve from 0.92500\n",
      "30/30 [==============================] - 6s 205ms/step - loss: 0.2755 - accuracy: 0.8854 - val_loss: 0.2411 - val_accuracy: 0.9250\n",
      "Epoch 22/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.2427 - accuracy: 0.8896\n",
      "Epoch 00022: val_accuracy did not improve from 0.92500\n",
      "30/30 [==============================] - 6s 206ms/step - loss: 0.2427 - accuracy: 0.8896 - val_loss: 0.3858 - val_accuracy: 0.8667\n",
      "Epoch 23/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.2353 - accuracy: 0.9042\n",
      "Epoch 00023: val_accuracy did not improve from 0.92500\n",
      "30/30 [==============================] - 6s 208ms/step - loss: 0.2353 - accuracy: 0.9042 - val_loss: 0.2565 - val_accuracy: 0.9167\n",
      "Epoch 24/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.2517 - accuracy: 0.8969\n",
      "Epoch 00024: val_accuracy did not improve from 0.92500\n",
      "30/30 [==============================] - 6s 207ms/step - loss: 0.2517 - accuracy: 0.8969 - val_loss: 0.2450 - val_accuracy: 0.9000\n",
      "Epoch 25/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.2279 - accuracy: 0.9198\n",
      "Epoch 00025: val_accuracy did not improve from 0.92500\n",
      "30/30 [==============================] - 6s 206ms/step - loss: 0.2279 - accuracy: 0.9198 - val_loss: 0.3428 - val_accuracy: 0.8208\n",
      "Epoch 26/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.2483 - accuracy: 0.8948\n",
      "Epoch 00026: val_accuracy did not improve from 0.92500\n",
      "30/30 [==============================] - 6s 205ms/step - loss: 0.2483 - accuracy: 0.8948 - val_loss: 0.2808 - val_accuracy: 0.9125\n",
      "Epoch 27/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.2731 - accuracy: 0.8958\n",
      "Epoch 00027: val_accuracy did not improve from 0.92500\n",
      "30/30 [==============================] - 6s 213ms/step - loss: 0.2731 - accuracy: 0.8958 - val_loss: 0.2777 - val_accuracy: 0.9000\n",
      "Epoch 28/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.2560 - accuracy: 0.8969\n",
      "Epoch 00028: val_accuracy did not improve from 0.92500\n",
      "30/30 [==============================] - 7s 218ms/step - loss: 0.2560 - accuracy: 0.8969 - val_loss: 0.2685 - val_accuracy: 0.9208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.2086 - accuracy: 0.9115\n",
      "Epoch 00029: val_accuracy did not improve from 0.92500\n",
      "30/30 [==============================] - 6s 206ms/step - loss: 0.2086 - accuracy: 0.9115 - val_loss: 0.2586 - val_accuracy: 0.9167\n",
      "Epoch 30/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.2253 - accuracy: 0.9000\n",
      "Epoch 00030: val_accuracy did not improve from 0.92500\n",
      "30/30 [==============================] - 6s 212ms/step - loss: 0.2253 - accuracy: 0.9000 - val_loss: 0.2422 - val_accuracy: 0.9042\n",
      "Epoch 31/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.2788 - accuracy: 0.8833\n",
      "Epoch 00031: val_accuracy did not improve from 0.92500\n",
      "30/30 [==============================] - 6s 206ms/step - loss: 0.2788 - accuracy: 0.8833 - val_loss: 0.2910 - val_accuracy: 0.8958\n",
      "Epoch 32/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.2544 - accuracy: 0.9031\n",
      "Epoch 00032: val_accuracy did not improve from 0.92500\n",
      "30/30 [==============================] - 6s 206ms/step - loss: 0.2544 - accuracy: 0.9031 - val_loss: 0.3027 - val_accuracy: 0.8750\n",
      "Epoch 33/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.2359 - accuracy: 0.8896\n",
      "Epoch 00033: val_accuracy did not improve from 0.92500\n",
      "30/30 [==============================] - 6s 205ms/step - loss: 0.2359 - accuracy: 0.8896 - val_loss: 0.2435 - val_accuracy: 0.9167\n",
      "Epoch 34/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1896 - accuracy: 0.9229\n",
      "Epoch 00034: val_accuracy improved from 0.92500 to 0.92917, saving model to ./class3/best_model.h5\n",
      "30/30 [==============================] - 7s 235ms/step - loss: 0.1896 - accuracy: 0.9229 - val_loss: 0.2189 - val_accuracy: 0.9292\n",
      "Epoch 35/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.2225 - accuracy: 0.9177\n",
      "Epoch 00035: val_accuracy did not improve from 0.92917\n",
      "30/30 [==============================] - 6s 203ms/step - loss: 0.2225 - accuracy: 0.9177 - val_loss: 0.2427 - val_accuracy: 0.9083\n",
      "Epoch 36/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1904 - accuracy: 0.9323\n",
      "Epoch 00036: val_accuracy did not improve from 0.92917\n",
      "30/30 [==============================] - 6s 210ms/step - loss: 0.1904 - accuracy: 0.9323 - val_loss: 0.2528 - val_accuracy: 0.8917\n",
      "Epoch 37/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1714 - accuracy: 0.9292\n",
      "Epoch 00037: val_accuracy did not improve from 0.92917\n",
      "30/30 [==============================] - 6s 204ms/step - loss: 0.1714 - accuracy: 0.9292 - val_loss: 0.2439 - val_accuracy: 0.9125\n",
      "Epoch 38/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.2498 - accuracy: 0.8990\n",
      "Epoch 00038: val_accuracy did not improve from 0.92917\n",
      "30/30 [==============================] - 6s 203ms/step - loss: 0.2498 - accuracy: 0.8990 - val_loss: 0.2433 - val_accuracy: 0.9083\n",
      "Epoch 39/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.2050 - accuracy: 0.9115\n",
      "Epoch 00039: val_accuracy did not improve from 0.92917\n",
      "30/30 [==============================] - 6s 201ms/step - loss: 0.2050 - accuracy: 0.9115 - val_loss: 0.2411 - val_accuracy: 0.9208\n",
      "Epoch 40/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.2161 - accuracy: 0.9083\n",
      "Epoch 00040: val_accuracy did not improve from 0.92917\n",
      "30/30 [==============================] - 6s 205ms/step - loss: 0.2161 - accuracy: 0.9083 - val_loss: 0.2638 - val_accuracy: 0.8792\n",
      "Epoch 41/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1884 - accuracy: 0.9281\n",
      "Epoch 00041: val_accuracy did not improve from 0.92917\n",
      "30/30 [==============================] - 6s 206ms/step - loss: 0.1884 - accuracy: 0.9281 - val_loss: 0.2122 - val_accuracy: 0.9167\n",
      "Epoch 42/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1838 - accuracy: 0.9260\n",
      "Epoch 00042: val_accuracy did not improve from 0.92917\n",
      "30/30 [==============================] - 6s 205ms/step - loss: 0.1838 - accuracy: 0.9260 - val_loss: 0.2622 - val_accuracy: 0.9125\n",
      "Epoch 43/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.2167 - accuracy: 0.9115\n",
      "Epoch 00043: val_accuracy did not improve from 0.92917\n",
      "30/30 [==============================] - 6s 204ms/step - loss: 0.2167 - accuracy: 0.9115 - val_loss: 0.3220 - val_accuracy: 0.8958\n",
      "Epoch 44/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1994 - accuracy: 0.9167\n",
      "Epoch 00044: val_accuracy did not improve from 0.92917\n",
      "30/30 [==============================] - 6s 202ms/step - loss: 0.1994 - accuracy: 0.9167 - val_loss: 0.2012 - val_accuracy: 0.9208\n",
      "Epoch 45/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1668 - accuracy: 0.9292\n",
      "Epoch 00045: val_accuracy did not improve from 0.92917\n",
      "30/30 [==============================] - 6s 202ms/step - loss: 0.1668 - accuracy: 0.9292 - val_loss: 0.2286 - val_accuracy: 0.9292\n",
      "Epoch 46/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1755 - accuracy: 0.9292\n",
      "Epoch 00046: val_accuracy did not improve from 0.92917\n",
      "30/30 [==============================] - 6s 203ms/step - loss: 0.1755 - accuracy: 0.9292 - val_loss: 0.1955 - val_accuracy: 0.9292\n",
      "Epoch 47/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.2331 - accuracy: 0.9083\n",
      "Epoch 00047: val_accuracy did not improve from 0.92917\n",
      "30/30 [==============================] - 6s 202ms/step - loss: 0.2331 - accuracy: 0.9083 - val_loss: 0.2347 - val_accuracy: 0.9250\n",
      "Epoch 48/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1751 - accuracy: 0.9302\n",
      "Epoch 00048: val_accuracy did not improve from 0.92917\n",
      "30/30 [==============================] - 6s 203ms/step - loss: 0.1751 - accuracy: 0.9302 - val_loss: 0.2087 - val_accuracy: 0.9292\n",
      "Epoch 49/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1812 - accuracy: 0.9323\n",
      "Epoch 00049: val_accuracy did not improve from 0.92917\n",
      "30/30 [==============================] - 6s 202ms/step - loss: 0.1812 - accuracy: 0.9323 - val_loss: 0.2417 - val_accuracy: 0.9125\n",
      "Epoch 50/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1989 - accuracy: 0.9187\n",
      "Epoch 00050: val_accuracy improved from 0.92917 to 0.93333, saving model to ./class3/best_model.h5\n",
      "30/30 [==============================] - 7s 231ms/step - loss: 0.1989 - accuracy: 0.9187 - val_loss: 0.1932 - val_accuracy: 0.9333\n",
      "Epoch 51/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.2133 - accuracy: 0.9115\n",
      "Epoch 00051: val_accuracy did not improve from 0.93333\n",
      "30/30 [==============================] - 6s 202ms/step - loss: 0.2133 - accuracy: 0.9115 - val_loss: 0.2100 - val_accuracy: 0.9292\n",
      "Epoch 52/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1889 - accuracy: 0.9271\n",
      "Epoch 00052: val_accuracy did not improve from 0.93333\n",
      "30/30 [==============================] - 6s 202ms/step - loss: 0.1889 - accuracy: 0.9271 - val_loss: 0.2125 - val_accuracy: 0.9125\n",
      "Epoch 53/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1859 - accuracy: 0.9312\n",
      "Epoch 00053: val_accuracy did not improve from 0.93333\n",
      "30/30 [==============================] - 6s 203ms/step - loss: 0.1859 - accuracy: 0.9312 - val_loss: 0.2387 - val_accuracy: 0.9083\n",
      "Epoch 54/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1861 - accuracy: 0.9260\n",
      "Epoch 00054: val_accuracy did not improve from 0.93333\n",
      "30/30 [==============================] - 6s 205ms/step - loss: 0.1861 - accuracy: 0.9260 - val_loss: 0.2093 - val_accuracy: 0.9250\n",
      "Epoch 55/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.2200 - accuracy: 0.9104\n",
      "Epoch 00055: val_accuracy improved from 0.93333 to 0.94167, saving model to ./class3/best_model.h5\n",
      "30/30 [==============================] - 7s 230ms/step - loss: 0.2200 - accuracy: 0.9104 - val_loss: 0.2004 - val_accuracy: 0.9417\n",
      "Epoch 56/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1603 - accuracy: 0.9396\n",
      "Epoch 00056: val_accuracy did not improve from 0.94167\n",
      "30/30 [==============================] - 6s 202ms/step - loss: 0.1603 - accuracy: 0.9396 - val_loss: 0.2012 - val_accuracy: 0.9375\n",
      "Epoch 57/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1501 - accuracy: 0.9458\n",
      "Epoch 00057: val_accuracy did not improve from 0.94167\n",
      "30/30 [==============================] - 6s 203ms/step - loss: 0.1501 - accuracy: 0.9458 - val_loss: 0.2181 - val_accuracy: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1726 - accuracy: 0.9281\n",
      "Epoch 00058: val_accuracy did not improve from 0.94167\n",
      "30/30 [==============================] - 6s 204ms/step - loss: 0.1726 - accuracy: 0.9281 - val_loss: 0.1760 - val_accuracy: 0.9333\n",
      "Epoch 59/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1345 - accuracy: 0.9510\n",
      "Epoch 00059: val_accuracy did not improve from 0.94167\n",
      "30/30 [==============================] - 6s 205ms/step - loss: 0.1345 - accuracy: 0.9510 - val_loss: 0.1751 - val_accuracy: 0.9417\n",
      "Epoch 60/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1874 - accuracy: 0.9208\n",
      "Epoch 00060: val_accuracy did not improve from 0.94167\n",
      "30/30 [==============================] - 6s 204ms/step - loss: 0.1874 - accuracy: 0.9208 - val_loss: 0.2245 - val_accuracy: 0.9125\n",
      "Epoch 61/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1644 - accuracy: 0.9292\n",
      "Epoch 00061: val_accuracy did not improve from 0.94167\n",
      "30/30 [==============================] - 6s 202ms/step - loss: 0.1644 - accuracy: 0.9292 - val_loss: 0.2593 - val_accuracy: 0.9208\n",
      "Epoch 62/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1549 - accuracy: 0.9375\n",
      "Epoch 00062: val_accuracy did not improve from 0.94167\n",
      "30/30 [==============================] - 6s 202ms/step - loss: 0.1549 - accuracy: 0.9375 - val_loss: 0.1999 - val_accuracy: 0.9375\n",
      "Epoch 63/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1656 - accuracy: 0.9365\n",
      "Epoch 00063: val_accuracy did not improve from 0.94167\n",
      "30/30 [==============================] - 6s 208ms/step - loss: 0.1656 - accuracy: 0.9365 - val_loss: 0.2037 - val_accuracy: 0.9292\n",
      "Epoch 64/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1536 - accuracy: 0.9354\n",
      "Epoch 00064: val_accuracy did not improve from 0.94167\n",
      "30/30 [==============================] - 6s 206ms/step - loss: 0.1536 - accuracy: 0.9354 - val_loss: 0.2050 - val_accuracy: 0.9042\n",
      "Epoch 65/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1864 - accuracy: 0.9292\n",
      "Epoch 00065: val_accuracy did not improve from 0.94167\n",
      "30/30 [==============================] - 6s 212ms/step - loss: 0.1864 - accuracy: 0.9292 - val_loss: 0.2009 - val_accuracy: 0.9375\n",
      "Epoch 66/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1692 - accuracy: 0.9292\n",
      "Epoch 00066: val_accuracy did not improve from 0.94167\n",
      "30/30 [==============================] - 6s 212ms/step - loss: 0.1692 - accuracy: 0.9292 - val_loss: 0.2182 - val_accuracy: 0.9333\n",
      "Epoch 67/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1647 - accuracy: 0.9385\n",
      "Epoch 00067: val_accuracy did not improve from 0.94167\n",
      "30/30 [==============================] - 6s 214ms/step - loss: 0.1647 - accuracy: 0.9385 - val_loss: 0.3196 - val_accuracy: 0.9042\n",
      "Epoch 68/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1380 - accuracy: 0.9417\n",
      "Epoch 00068: val_accuracy did not improve from 0.94167\n",
      "30/30 [==============================] - 6s 210ms/step - loss: 0.1380 - accuracy: 0.9417 - val_loss: 0.2075 - val_accuracy: 0.9250\n",
      "Epoch 69/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1539 - accuracy: 0.9427\n",
      "Epoch 00069: val_accuracy did not improve from 0.94167\n",
      "30/30 [==============================] - 6s 208ms/step - loss: 0.1539 - accuracy: 0.9427 - val_loss: 0.1959 - val_accuracy: 0.9292\n",
      "Epoch 70/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1548 - accuracy: 0.9417\n",
      "Epoch 00070: val_accuracy did not improve from 0.94167\n",
      "30/30 [==============================] - 6s 213ms/step - loss: 0.1548 - accuracy: 0.9417 - val_loss: 0.2075 - val_accuracy: 0.9333\n",
      "Epoch 71/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1589 - accuracy: 0.9375\n",
      "Epoch 00071: val_accuracy did not improve from 0.94167\n",
      "30/30 [==============================] - 6s 210ms/step - loss: 0.1589 - accuracy: 0.9375 - val_loss: 0.2182 - val_accuracy: 0.9250\n",
      "Epoch 72/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1870 - accuracy: 0.9292\n",
      "Epoch 00072: val_accuracy did not improve from 0.94167\n",
      "30/30 [==============================] - 6s 210ms/step - loss: 0.1870 - accuracy: 0.9292 - val_loss: 0.1981 - val_accuracy: 0.9292\n",
      "Epoch 73/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1528 - accuracy: 0.9417\n",
      "Epoch 00073: val_accuracy did not improve from 0.94167\n",
      "30/30 [==============================] - 6s 211ms/step - loss: 0.1528 - accuracy: 0.9417 - val_loss: 0.2075 - val_accuracy: 0.9292\n",
      "Epoch 74/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1468 - accuracy: 0.9458\n",
      "Epoch 00074: val_accuracy did not improve from 0.94167\n",
      "30/30 [==============================] - 7s 220ms/step - loss: 0.1468 - accuracy: 0.9458 - val_loss: 0.2024 - val_accuracy: 0.9333\n",
      "Epoch 75/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1559 - accuracy: 0.9365\n",
      "Epoch 00075: val_accuracy did not improve from 0.94167\n",
      "30/30 [==============================] - 6s 211ms/step - loss: 0.1559 - accuracy: 0.9365 - val_loss: 0.2014 - val_accuracy: 0.9292\n",
      "Epoch 76/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1574 - accuracy: 0.9302\n",
      "Epoch 00076: val_accuracy did not improve from 0.94167\n",
      "30/30 [==============================] - 6s 211ms/step - loss: 0.1574 - accuracy: 0.9302 - val_loss: 0.2013 - val_accuracy: 0.9333\n",
      "Epoch 77/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1522 - accuracy: 0.9396\n",
      "Epoch 00077: val_accuracy did not improve from 0.94167\n",
      "30/30 [==============================] - 7s 216ms/step - loss: 0.1522 - accuracy: 0.9396 - val_loss: 0.1936 - val_accuracy: 0.9375\n",
      "Epoch 78/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1700 - accuracy: 0.9333\n",
      "Epoch 00078: val_accuracy did not improve from 0.94167\n",
      "30/30 [==============================] - 7s 216ms/step - loss: 0.1700 - accuracy: 0.9333 - val_loss: 0.2149 - val_accuracy: 0.9375\n",
      "Epoch 79/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1434 - accuracy: 0.9354\n",
      "Epoch 00079: val_accuracy did not improve from 0.94167\n",
      "30/30 [==============================] - 7s 217ms/step - loss: 0.1434 - accuracy: 0.9354 - val_loss: 0.2599 - val_accuracy: 0.8958\n",
      "Epoch 80/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1488 - accuracy: 0.9406\n",
      "Epoch 00080: val_accuracy did not improve from 0.94167\n",
      "30/30 [==============================] - 7s 220ms/step - loss: 0.1488 - accuracy: 0.9406 - val_loss: 0.2097 - val_accuracy: 0.9042\n",
      "Epoch 81/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1639 - accuracy: 0.9458\n",
      "Epoch 00081: val_accuracy did not improve from 0.94167\n",
      "30/30 [==============================] - 7s 216ms/step - loss: 0.1639 - accuracy: 0.9458 - val_loss: 0.2447 - val_accuracy: 0.9083\n",
      "Epoch 82/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1677 - accuracy: 0.9427\n",
      "Epoch 00082: val_accuracy did not improve from 0.94167\n",
      "30/30 [==============================] - 7s 217ms/step - loss: 0.1677 - accuracy: 0.9427 - val_loss: 0.3024 - val_accuracy: 0.9000\n",
      "Epoch 83/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1388 - accuracy: 0.9438\n",
      "Epoch 00083: val_accuracy did not improve from 0.94167\n",
      "30/30 [==============================] - 7s 221ms/step - loss: 0.1388 - accuracy: 0.9438 - val_loss: 0.2158 - val_accuracy: 0.9375\n",
      "Epoch 84/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1677 - accuracy: 0.9354\n",
      "Epoch 00084: val_accuracy did not improve from 0.94167\n",
      "30/30 [==============================] - 6s 208ms/step - loss: 0.1677 - accuracy: 0.9354 - val_loss: 0.2003 - val_accuracy: 0.9292\n",
      "Epoch 85/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1431 - accuracy: 0.9458\n",
      "Epoch 00085: val_accuracy did not improve from 0.94167\n",
      "30/30 [==============================] - 7s 215ms/step - loss: 0.1431 - accuracy: 0.9458 - val_loss: 0.1895 - val_accuracy: 0.9333\n",
      "Epoch 86/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1598 - accuracy: 0.9385\n",
      "Epoch 00086: val_accuracy did not improve from 0.94167\n",
      "30/30 [==============================] - 7s 219ms/step - loss: 0.1598 - accuracy: 0.9385 - val_loss: 0.2847 - val_accuracy: 0.9042\n",
      "Epoch 87/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - ETA: 0s - loss: 0.1410 - accuracy: 0.9479\n",
      "Epoch 00087: val_accuracy did not improve from 0.94167\n",
      "30/30 [==============================] - 6s 214ms/step - loss: 0.1410 - accuracy: 0.9479 - val_loss: 0.2215 - val_accuracy: 0.9333\n",
      "Epoch 88/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1593 - accuracy: 0.9333\n",
      "Epoch 00088: val_accuracy did not improve from 0.94167\n",
      "30/30 [==============================] - 6s 212ms/step - loss: 0.1593 - accuracy: 0.9333 - val_loss: 0.1965 - val_accuracy: 0.9333\n",
      "Epoch 89/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1558 - accuracy: 0.9500\n",
      "Epoch 00089: val_accuracy did not improve from 0.94167\n",
      "30/30 [==============================] - 7s 216ms/step - loss: 0.1558 - accuracy: 0.9500 - val_loss: 0.2186 - val_accuracy: 0.9333\n",
      "Epoch 90/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1361 - accuracy: 0.9469\n",
      "Epoch 00090: val_accuracy did not improve from 0.94167\n",
      "30/30 [==============================] - 6s 212ms/step - loss: 0.1361 - accuracy: 0.9469 - val_loss: 0.2219 - val_accuracy: 0.9375\n",
      "Epoch 91/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1314 - accuracy: 0.9427\n",
      "Epoch 00091: val_accuracy did not improve from 0.94167\n",
      "30/30 [==============================] - 7s 217ms/step - loss: 0.1314 - accuracy: 0.9427 - val_loss: 0.1904 - val_accuracy: 0.9208\n",
      "Epoch 92/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1241 - accuracy: 0.9521\n",
      "Epoch 00092: val_accuracy did not improve from 0.94167\n",
      "30/30 [==============================] - 7s 216ms/step - loss: 0.1241 - accuracy: 0.9521 - val_loss: 0.1801 - val_accuracy: 0.9292\n",
      "Epoch 93/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1498 - accuracy: 0.9385\n",
      "Epoch 00093: val_accuracy did not improve from 0.94167\n",
      "30/30 [==============================] - 7s 215ms/step - loss: 0.1498 - accuracy: 0.9385 - val_loss: 0.1737 - val_accuracy: 0.9417\n",
      "Epoch 94/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1309 - accuracy: 0.9448\n",
      "Epoch 00094: val_accuracy did not improve from 0.94167\n",
      "30/30 [==============================] - 6s 211ms/step - loss: 0.1309 - accuracy: 0.9448 - val_loss: 0.2398 - val_accuracy: 0.9250\n",
      "Epoch 95/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1366 - accuracy: 0.9490\n",
      "Epoch 00095: val_accuracy improved from 0.94167 to 0.95417, saving model to ./class3/best_model.h5\n",
      "30/30 [==============================] - 7s 241ms/step - loss: 0.1366 - accuracy: 0.9490 - val_loss: 0.2070 - val_accuracy: 0.9542\n",
      "Epoch 96/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1592 - accuracy: 0.9365\n",
      "Epoch 00096: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 6s 212ms/step - loss: 0.1592 - accuracy: 0.9365 - val_loss: 0.2056 - val_accuracy: 0.9375\n",
      "Epoch 97/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1230 - accuracy: 0.9490\n",
      "Epoch 00097: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 6s 210ms/step - loss: 0.1230 - accuracy: 0.9490 - val_loss: 0.1804 - val_accuracy: 0.9333\n",
      "Epoch 98/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1161 - accuracy: 0.9563\n",
      "Epoch 00098: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 6s 210ms/step - loss: 0.1161 - accuracy: 0.9563 - val_loss: 0.3101 - val_accuracy: 0.8875\n",
      "Epoch 99/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1643 - accuracy: 0.9365\n",
      "Epoch 00099: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 7s 216ms/step - loss: 0.1643 - accuracy: 0.9365 - val_loss: 0.1898 - val_accuracy: 0.9375\n",
      "Epoch 100/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1170 - accuracy: 0.9521\n",
      "Epoch 00100: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 6s 212ms/step - loss: 0.1170 - accuracy: 0.9521 - val_loss: 0.2040 - val_accuracy: 0.9375\n",
      "Epoch 101/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1152 - accuracy: 0.9531\n",
      "Epoch 00101: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 7s 219ms/step - loss: 0.1152 - accuracy: 0.9531 - val_loss: 0.1904 - val_accuracy: 0.9292\n",
      "Epoch 102/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1112 - accuracy: 0.9604\n",
      "Epoch 00102: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 6s 212ms/step - loss: 0.1112 - accuracy: 0.9604 - val_loss: 0.2718 - val_accuracy: 0.9167\n",
      "Epoch 103/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1312 - accuracy: 0.9500\n",
      "Epoch 00103: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 7s 216ms/step - loss: 0.1312 - accuracy: 0.9500 - val_loss: 0.1986 - val_accuracy: 0.9333\n",
      "Epoch 104/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1208 - accuracy: 0.9427\n",
      "Epoch 00104: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 7s 216ms/step - loss: 0.1208 - accuracy: 0.9427 - val_loss: 0.2045 - val_accuracy: 0.9292\n",
      "Epoch 105/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1096 - accuracy: 0.9510\n",
      "Epoch 00105: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 7s 215ms/step - loss: 0.1096 - accuracy: 0.9510 - val_loss: 0.1966 - val_accuracy: 0.9375\n",
      "Epoch 106/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1147 - accuracy: 0.9542\n",
      "Epoch 00106: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 7s 215ms/step - loss: 0.1147 - accuracy: 0.9542 - val_loss: 0.2146 - val_accuracy: 0.9292\n",
      "Epoch 107/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1344 - accuracy: 0.9406\n",
      "Epoch 00107: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 7s 215ms/step - loss: 0.1344 - accuracy: 0.9406 - val_loss: 0.4618 - val_accuracy: 0.8792\n",
      "Epoch 108/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1329 - accuracy: 0.9438\n",
      "Epoch 00108: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 6s 213ms/step - loss: 0.1329 - accuracy: 0.9438 - val_loss: 0.2239 - val_accuracy: 0.9250\n",
      "Epoch 109/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1383 - accuracy: 0.9438\n",
      "Epoch 00109: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 6s 212ms/step - loss: 0.1383 - accuracy: 0.9438 - val_loss: 0.2137 - val_accuracy: 0.9333\n",
      "Epoch 110/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1218 - accuracy: 0.9552\n",
      "Epoch 00110: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 6s 209ms/step - loss: 0.1218 - accuracy: 0.9552 - val_loss: 0.1877 - val_accuracy: 0.9375\n",
      "Epoch 111/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1150 - accuracy: 0.9552\n",
      "Epoch 00111: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 7s 216ms/step - loss: 0.1150 - accuracy: 0.9552 - val_loss: 0.2597 - val_accuracy: 0.9125\n",
      "Epoch 112/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1440 - accuracy: 0.9479\n",
      "Epoch 00112: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 6s 211ms/step - loss: 0.1440 - accuracy: 0.9479 - val_loss: 0.1789 - val_accuracy: 0.9417\n",
      "Epoch 113/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1233 - accuracy: 0.9438\n",
      "Epoch 00113: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 6s 209ms/step - loss: 0.1233 - accuracy: 0.9438 - val_loss: 0.2066 - val_accuracy: 0.9208\n",
      "Epoch 114/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1432 - accuracy: 0.9438\n",
      "Epoch 00114: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 6s 209ms/step - loss: 0.1432 - accuracy: 0.9438 - val_loss: 0.2695 - val_accuracy: 0.9292\n",
      "Epoch 115/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1078 - accuracy: 0.9500\n",
      "Epoch 00115: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 6s 210ms/step - loss: 0.1078 - accuracy: 0.9500 - val_loss: 0.2170 - val_accuracy: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1456 - accuracy: 0.9490\n",
      "Epoch 00116: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 6s 209ms/step - loss: 0.1456 - accuracy: 0.9490 - val_loss: 0.2453 - val_accuracy: 0.9333\n",
      "Epoch 117/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1363 - accuracy: 0.9458\n",
      "Epoch 00117: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 6s 208ms/step - loss: 0.1363 - accuracy: 0.9458 - val_loss: 0.2864 - val_accuracy: 0.9042\n",
      "Epoch 118/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1222 - accuracy: 0.9490\n",
      "Epoch 00118: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 6s 210ms/step - loss: 0.1222 - accuracy: 0.9490 - val_loss: 0.2121 - val_accuracy: 0.9458\n",
      "Epoch 119/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1137 - accuracy: 0.9521\n",
      "Epoch 00119: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 6s 209ms/step - loss: 0.1137 - accuracy: 0.9521 - val_loss: 0.1710 - val_accuracy: 0.9375\n",
      "Epoch 120/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1063 - accuracy: 0.9552\n",
      "Epoch 00120: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 6s 210ms/step - loss: 0.1063 - accuracy: 0.9552 - val_loss: 0.2028 - val_accuracy: 0.9125\n",
      "Epoch 121/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1263 - accuracy: 0.9469\n",
      "Epoch 00121: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 6s 212ms/step - loss: 0.1263 - accuracy: 0.9469 - val_loss: 0.2569 - val_accuracy: 0.9333\n",
      "Epoch 122/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1153 - accuracy: 0.9531\n",
      "Epoch 00122: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 6s 211ms/step - loss: 0.1153 - accuracy: 0.9531 - val_loss: 0.1796 - val_accuracy: 0.9458\n",
      "Epoch 123/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1505 - accuracy: 0.9427\n",
      "Epoch 00123: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 6s 211ms/step - loss: 0.1505 - accuracy: 0.9427 - val_loss: 0.2289 - val_accuracy: 0.9375\n",
      "Epoch 124/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1152 - accuracy: 0.9573\n",
      "Epoch 00124: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 6s 209ms/step - loss: 0.1152 - accuracy: 0.9573 - val_loss: 0.2598 - val_accuracy: 0.9417\n",
      "Epoch 125/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1569 - accuracy: 0.9427\n",
      "Epoch 00125: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 6s 210ms/step - loss: 0.1569 - accuracy: 0.9427 - val_loss: 0.2387 - val_accuracy: 0.9458\n",
      "Epoch 126/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1336 - accuracy: 0.9500\n",
      "Epoch 00126: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 6s 208ms/step - loss: 0.1336 - accuracy: 0.9500 - val_loss: 0.2263 - val_accuracy: 0.9375\n",
      "Epoch 127/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1299 - accuracy: 0.9417\n",
      "Epoch 00127: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 6s 209ms/step - loss: 0.1299 - accuracy: 0.9417 - val_loss: 0.1959 - val_accuracy: 0.9250\n",
      "Epoch 128/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1412 - accuracy: 0.9531\n",
      "Epoch 00128: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 6s 207ms/step - loss: 0.1412 - accuracy: 0.9531 - val_loss: 0.1752 - val_accuracy: 0.9500\n",
      "Epoch 129/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1354 - accuracy: 0.9458\n",
      "Epoch 00129: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 6s 210ms/step - loss: 0.1354 - accuracy: 0.9458 - val_loss: 0.1543 - val_accuracy: 0.9542\n",
      "Epoch 130/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1152 - accuracy: 0.9542\n",
      "Epoch 00130: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 6s 209ms/step - loss: 0.1152 - accuracy: 0.9542 - val_loss: 0.2431 - val_accuracy: 0.9292\n",
      "Epoch 131/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1129 - accuracy: 0.9521\n",
      "Epoch 00131: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 6s 210ms/step - loss: 0.1129 - accuracy: 0.9521 - val_loss: 0.2965 - val_accuracy: 0.9292\n",
      "Epoch 132/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1410 - accuracy: 0.9448\n",
      "Epoch 00132: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 6s 211ms/step - loss: 0.1410 - accuracy: 0.9448 - val_loss: 0.2684 - val_accuracy: 0.9292\n",
      "Epoch 133/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1096 - accuracy: 0.9542\n",
      "Epoch 00133: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 6s 209ms/step - loss: 0.1096 - accuracy: 0.9542 - val_loss: 0.2058 - val_accuracy: 0.9292\n",
      "Epoch 134/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1270 - accuracy: 0.9458\n",
      "Epoch 00134: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 6s 209ms/step - loss: 0.1270 - accuracy: 0.9458 - val_loss: 0.1943 - val_accuracy: 0.9458\n",
      "Epoch 135/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1016 - accuracy: 0.9625\n",
      "Epoch 00135: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 6s 210ms/step - loss: 0.1016 - accuracy: 0.9625 - val_loss: 0.2495 - val_accuracy: 0.9458\n",
      "Epoch 136/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0810 - accuracy: 0.9667\n",
      "Epoch 00136: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 6s 209ms/step - loss: 0.0810 - accuracy: 0.9667 - val_loss: 0.2401 - val_accuracy: 0.9458\n",
      "Epoch 137/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1273 - accuracy: 0.9552\n",
      "Epoch 00137: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 6s 210ms/step - loss: 0.1273 - accuracy: 0.9552 - val_loss: 0.1685 - val_accuracy: 0.9208\n",
      "Epoch 138/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1026 - accuracy: 0.9604\n",
      "Epoch 00138: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 6s 210ms/step - loss: 0.1026 - accuracy: 0.9604 - val_loss: 0.1681 - val_accuracy: 0.9250\n",
      "Epoch 139/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1176 - accuracy: 0.9448\n",
      "Epoch 00139: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 6s 210ms/step - loss: 0.1176 - accuracy: 0.9448 - val_loss: 0.1980 - val_accuracy: 0.9417\n",
      "Epoch 140/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1055 - accuracy: 0.9625\n",
      "Epoch 00140: val_accuracy did not improve from 0.95417\n",
      "30/30 [==============================] - 6s 211ms/step - loss: 0.1055 - accuracy: 0.9625 - val_loss: 0.1702 - val_accuracy: 0.9500\n",
      "Epoch 141/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0860 - accuracy: 0.9646\n",
      "Epoch 00141: val_accuracy improved from 0.95417 to 0.95833, saving model to ./class3/best_model.h5\n",
      "30/30 [==============================] - 7s 239ms/step - loss: 0.0860 - accuracy: 0.9646 - val_loss: 0.1931 - val_accuracy: 0.9583\n",
      "Epoch 142/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0914 - accuracy: 0.9594\n",
      "Epoch 00142: val_accuracy did not improve from 0.95833\n",
      "30/30 [==============================] - 6s 210ms/step - loss: 0.0914 - accuracy: 0.9594 - val_loss: 0.2008 - val_accuracy: 0.9500\n",
      "Epoch 143/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1084 - accuracy: 0.9531\n",
      "Epoch 00143: val_accuracy did not improve from 0.95833\n",
      "30/30 [==============================] - 6s 210ms/step - loss: 0.1084 - accuracy: 0.9531 - val_loss: 0.2157 - val_accuracy: 0.9500\n",
      "Epoch 144/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0912 - accuracy: 0.9646\n",
      "Epoch 00144: val_accuracy did not improve from 0.95833\n",
      "30/30 [==============================] - 6s 210ms/step - loss: 0.0912 - accuracy: 0.9646 - val_loss: 0.1913 - val_accuracy: 0.9583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0989 - accuracy: 0.9615\n",
      "Epoch 00145: val_accuracy did not improve from 0.95833\n",
      "30/30 [==============================] - 6s 209ms/step - loss: 0.0989 - accuracy: 0.9615 - val_loss: 0.2331 - val_accuracy: 0.9375\n",
      "Epoch 146/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1068 - accuracy: 0.9573\n",
      "Epoch 00146: val_accuracy did not improve from 0.95833\n",
      "30/30 [==============================] - 6s 208ms/step - loss: 0.1068 - accuracy: 0.9573 - val_loss: 0.2294 - val_accuracy: 0.9375\n",
      "Epoch 147/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1009 - accuracy: 0.9625\n",
      "Epoch 00147: val_accuracy did not improve from 0.95833\n",
      "30/30 [==============================] - 6s 210ms/step - loss: 0.1009 - accuracy: 0.9625 - val_loss: 0.1883 - val_accuracy: 0.9583\n",
      "Epoch 148/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0944 - accuracy: 0.9635\n",
      "Epoch 00148: val_accuracy did not improve from 0.95833\n",
      "30/30 [==============================] - 6s 210ms/step - loss: 0.0944 - accuracy: 0.9635 - val_loss: 0.1930 - val_accuracy: 0.9542\n",
      "Epoch 149/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1236 - accuracy: 0.9510\n",
      "Epoch 00149: val_accuracy did not improve from 0.95833\n",
      "30/30 [==============================] - 6s 208ms/step - loss: 0.1236 - accuracy: 0.9510 - val_loss: 0.2167 - val_accuracy: 0.9458\n",
      "Epoch 150/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1006 - accuracy: 0.9635\n",
      "Epoch 00150: val_accuracy did not improve from 0.95833\n",
      "30/30 [==============================] - 6s 210ms/step - loss: 0.1006 - accuracy: 0.9635 - val_loss: 0.2482 - val_accuracy: 0.9292\n",
      "Epoch 151/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1025 - accuracy: 0.9552\n",
      "Epoch 00151: val_accuracy did not improve from 0.95833\n",
      "30/30 [==============================] - 6s 209ms/step - loss: 0.1025 - accuracy: 0.9552 - val_loss: 0.1543 - val_accuracy: 0.9542\n",
      "Epoch 152/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0851 - accuracy: 0.9677\n",
      "Epoch 00152: val_accuracy improved from 0.95833 to 0.96667, saving model to ./class3/best_model.h5\n",
      "30/30 [==============================] - 7s 238ms/step - loss: 0.0851 - accuracy: 0.9677 - val_loss: 0.1562 - val_accuracy: 0.9667\n",
      "Epoch 153/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0848 - accuracy: 0.9677\n",
      "Epoch 00153: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 210ms/step - loss: 0.0848 - accuracy: 0.9677 - val_loss: 0.1999 - val_accuracy: 0.9583\n",
      "Epoch 154/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0903 - accuracy: 0.9656\n",
      "Epoch 00154: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 209ms/step - loss: 0.0903 - accuracy: 0.9656 - val_loss: 0.1762 - val_accuracy: 0.9500\n",
      "Epoch 155/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1331 - accuracy: 0.9479\n",
      "Epoch 00155: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 209ms/step - loss: 0.1331 - accuracy: 0.9479 - val_loss: 0.3010 - val_accuracy: 0.9208\n",
      "Epoch 156/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1159 - accuracy: 0.9563\n",
      "Epoch 00156: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 210ms/step - loss: 0.1159 - accuracy: 0.9563 - val_loss: 0.1717 - val_accuracy: 0.9542\n",
      "Epoch 157/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0969 - accuracy: 0.9646\n",
      "Epoch 00157: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 208ms/step - loss: 0.0969 - accuracy: 0.9646 - val_loss: 0.2212 - val_accuracy: 0.9458\n",
      "Epoch 158/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0817 - accuracy: 0.9688\n",
      "Epoch 00158: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 209ms/step - loss: 0.0817 - accuracy: 0.9688 - val_loss: 0.1842 - val_accuracy: 0.9500\n",
      "Epoch 159/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0926 - accuracy: 0.9656\n",
      "Epoch 00159: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 210ms/step - loss: 0.0926 - accuracy: 0.9656 - val_loss: 0.1594 - val_accuracy: 0.9583\n",
      "Epoch 160/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0919 - accuracy: 0.9667\n",
      "Epoch 00160: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 210ms/step - loss: 0.0919 - accuracy: 0.9667 - val_loss: 0.2011 - val_accuracy: 0.9417\n",
      "Epoch 161/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0762 - accuracy: 0.9698\n",
      "Epoch 00161: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 209ms/step - loss: 0.0762 - accuracy: 0.9698 - val_loss: 0.2194 - val_accuracy: 0.9500\n",
      "Epoch 162/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1064 - accuracy: 0.9552\n",
      "Epoch 00162: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 211ms/step - loss: 0.1064 - accuracy: 0.9552 - val_loss: 0.2332 - val_accuracy: 0.9583\n",
      "Epoch 163/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0960 - accuracy: 0.9615\n",
      "Epoch 00163: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 209ms/step - loss: 0.0960 - accuracy: 0.9615 - val_loss: 0.2338 - val_accuracy: 0.9458\n",
      "Epoch 164/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1209 - accuracy: 0.9531\n",
      "Epoch 00164: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 210ms/step - loss: 0.1209 - accuracy: 0.9531 - val_loss: 0.2112 - val_accuracy: 0.9417\n",
      "Epoch 165/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1127 - accuracy: 0.9604\n",
      "Epoch 00165: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 208ms/step - loss: 0.1127 - accuracy: 0.9604 - val_loss: 0.1584 - val_accuracy: 0.9500\n",
      "Epoch 166/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0941 - accuracy: 0.9573\n",
      "Epoch 00166: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 209ms/step - loss: 0.0941 - accuracy: 0.9573 - val_loss: 0.1763 - val_accuracy: 0.9458\n",
      "Epoch 167/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1019 - accuracy: 0.9615\n",
      "Epoch 00167: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 210ms/step - loss: 0.1019 - accuracy: 0.9615 - val_loss: 0.2184 - val_accuracy: 0.9417\n",
      "Epoch 168/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1189 - accuracy: 0.9625\n",
      "Epoch 00168: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 209ms/step - loss: 0.1189 - accuracy: 0.9625 - val_loss: 0.2542 - val_accuracy: 0.9292\n",
      "Epoch 169/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1045 - accuracy: 0.9552\n",
      "Epoch 00169: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 210ms/step - loss: 0.1045 - accuracy: 0.9552 - val_loss: 0.1987 - val_accuracy: 0.9417\n",
      "Epoch 170/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1170 - accuracy: 0.9563\n",
      "Epoch 00170: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 210ms/step - loss: 0.1170 - accuracy: 0.9563 - val_loss: 0.2175 - val_accuracy: 0.9417\n",
      "Epoch 171/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0642 - accuracy: 0.9740\n",
      "Epoch 00171: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 211ms/step - loss: 0.0642 - accuracy: 0.9740 - val_loss: 0.2108 - val_accuracy: 0.9542\n",
      "Epoch 172/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0885 - accuracy: 0.9615\n",
      "Epoch 00172: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 210ms/step - loss: 0.0885 - accuracy: 0.9615 - val_loss: 0.1795 - val_accuracy: 0.9542\n",
      "Epoch 173/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1169 - accuracy: 0.9552\n",
      "Epoch 00173: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 213ms/step - loss: 0.1169 - accuracy: 0.9552 - val_loss: 0.2249 - val_accuracy: 0.9417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0859 - accuracy: 0.9635\n",
      "Epoch 00174: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 212ms/step - loss: 0.0859 - accuracy: 0.9635 - val_loss: 0.1948 - val_accuracy: 0.9625\n",
      "Epoch 175/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0942 - accuracy: 0.9656\n",
      "Epoch 00175: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 210ms/step - loss: 0.0942 - accuracy: 0.9656 - val_loss: 0.1864 - val_accuracy: 0.9500\n",
      "Epoch 176/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0918 - accuracy: 0.9625\n",
      "Epoch 00176: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 210ms/step - loss: 0.0918 - accuracy: 0.9625 - val_loss: 0.2012 - val_accuracy: 0.9625\n",
      "Epoch 177/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0995 - accuracy: 0.9594\n",
      "Epoch 00177: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 213ms/step - loss: 0.0995 - accuracy: 0.9594 - val_loss: 0.1763 - val_accuracy: 0.9542\n",
      "Epoch 178/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0824 - accuracy: 0.9646\n",
      "Epoch 00178: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 212ms/step - loss: 0.0824 - accuracy: 0.9646 - val_loss: 0.2016 - val_accuracy: 0.9542\n",
      "Epoch 179/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0751 - accuracy: 0.9698\n",
      "Epoch 00179: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 213ms/step - loss: 0.0751 - accuracy: 0.9698 - val_loss: 0.2521 - val_accuracy: 0.9417\n",
      "Epoch 180/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1075 - accuracy: 0.9625\n",
      "Epoch 00180: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 211ms/step - loss: 0.1075 - accuracy: 0.9625 - val_loss: 0.2158 - val_accuracy: 0.9542\n",
      "Epoch 181/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1006 - accuracy: 0.9604\n",
      "Epoch 00181: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 210ms/step - loss: 0.1006 - accuracy: 0.9604 - val_loss: 0.1922 - val_accuracy: 0.9375\n",
      "Epoch 182/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1062 - accuracy: 0.9604\n",
      "Epoch 00182: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 210ms/step - loss: 0.1062 - accuracy: 0.9604 - val_loss: 0.2095 - val_accuracy: 0.9458\n",
      "Epoch 183/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0864 - accuracy: 0.9635\n",
      "Epoch 00183: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 211ms/step - loss: 0.0864 - accuracy: 0.9635 - val_loss: 0.2783 - val_accuracy: 0.9250\n",
      "Epoch 184/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0836 - accuracy: 0.9708\n",
      "Epoch 00184: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 207ms/step - loss: 0.0836 - accuracy: 0.9708 - val_loss: 0.2218 - val_accuracy: 0.9417\n",
      "Epoch 185/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0741 - accuracy: 0.9698\n",
      "Epoch 00185: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 209ms/step - loss: 0.0741 - accuracy: 0.9698 - val_loss: 0.1975 - val_accuracy: 0.9625\n",
      "Epoch 186/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0802 - accuracy: 0.9688\n",
      "Epoch 00186: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 211ms/step - loss: 0.0802 - accuracy: 0.9688 - val_loss: 0.1807 - val_accuracy: 0.9458\n",
      "Epoch 187/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1133 - accuracy: 0.9542\n",
      "Epoch 00187: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 214ms/step - loss: 0.1133 - accuracy: 0.9542 - val_loss: 0.1812 - val_accuracy: 0.9500\n",
      "Epoch 188/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1318 - accuracy: 0.9500\n",
      "Epoch 00188: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 211ms/step - loss: 0.1318 - accuracy: 0.9500 - val_loss: 0.6033 - val_accuracy: 0.8375\n",
      "Epoch 189/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1370 - accuracy: 0.9385\n",
      "Epoch 00189: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 210ms/step - loss: 0.1370 - accuracy: 0.9385 - val_loss: 0.1619 - val_accuracy: 0.9458\n",
      "Epoch 190/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0911 - accuracy: 0.9698\n",
      "Epoch 00190: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 7s 217ms/step - loss: 0.0911 - accuracy: 0.9698 - val_loss: 0.2042 - val_accuracy: 0.9458\n",
      "Epoch 191/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1021 - accuracy: 0.9583\n",
      "Epoch 00191: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 211ms/step - loss: 0.1021 - accuracy: 0.9583 - val_loss: 0.1794 - val_accuracy: 0.9500\n",
      "Epoch 192/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1021 - accuracy: 0.9542\n",
      "Epoch 00192: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 212ms/step - loss: 0.1021 - accuracy: 0.9542 - val_loss: 0.2103 - val_accuracy: 0.9500\n",
      "Epoch 193/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0913 - accuracy: 0.9677\n",
      "Epoch 00193: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 212ms/step - loss: 0.0913 - accuracy: 0.9677 - val_loss: 0.1873 - val_accuracy: 0.9458\n",
      "Epoch 194/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0896 - accuracy: 0.9615\n",
      "Epoch 00194: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 213ms/step - loss: 0.0896 - accuracy: 0.9615 - val_loss: 0.2723 - val_accuracy: 0.9417\n",
      "Epoch 195/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0728 - accuracy: 0.9771\n",
      "Epoch 00195: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 208ms/step - loss: 0.0728 - accuracy: 0.9771 - val_loss: 0.2274 - val_accuracy: 0.9458\n",
      "Epoch 196/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0773 - accuracy: 0.9729\n",
      "Epoch 00196: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 208ms/step - loss: 0.0773 - accuracy: 0.9729 - val_loss: 0.1917 - val_accuracy: 0.9500\n",
      "Epoch 197/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.1007 - accuracy: 0.9573\n",
      "Epoch 00197: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 206ms/step - loss: 0.1007 - accuracy: 0.9573 - val_loss: 0.3087 - val_accuracy: 0.9083\n",
      "Epoch 198/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0884 - accuracy: 0.9698\n",
      "Epoch 00198: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 210ms/step - loss: 0.0884 - accuracy: 0.9698 - val_loss: 0.2320 - val_accuracy: 0.9542\n",
      "Epoch 199/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0974 - accuracy: 0.9667\n",
      "Epoch 00199: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 213ms/step - loss: 0.0974 - accuracy: 0.9667 - val_loss: 0.1868 - val_accuracy: 0.9542\n",
      "Epoch 200/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0904 - accuracy: 0.9719\n",
      "Epoch 00200: val_accuracy did not improve from 0.96667\n",
      "30/30 [==============================] - 6s 210ms/step - loss: 0.0904 - accuracy: 0.9719 - val_loss: 0.1373 - val_accuracy: 0.9500\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=test_generator,\n",
    "    epochs=200,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[checkpoint, tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e70da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard --logdir=./class3_logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hello] *",
   "language": "python",
   "name": "conda-env-hello-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
